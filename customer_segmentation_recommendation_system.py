# -*- coding: utf-8 -*-
"""Customer_Segmentation_Recommendation_System.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QZ3A-Qwe4Q74MEQLfNEfnZFEzr0wObJb
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
from sklearn.metrics.pairwise import cosine_similarity
import random

df = pd.read_csv('data.csv',encoding = "ISO-8859-1")

df.head()

df.info()

# description, customer ID have missing values

df.shape

df.columns

df.dtypes

df.describe()

"""<h4>
The dataset corresponds to the sales of a UK-based and registered non-store online retail in a specific timeline.
    
The mean unit price of the commodities sold by this Retail is 4.61 pounds. The maximum unit price of a particular product is 38970, which is probably a luxury product.

The Retail sold a total of 541,909 items from 01/12/2010 and 09/12/2011. It sells around 10 items in each transaction on average, and it makes sense because the main customers are wholesalers.

The maximum number of items sold in one transaction is 80995.

The number of Customers registered in the database is 406829. A large number of customers aren't registered.

</h4>
"""

df.isnull().sum()

"""<h4>There are Null Values present in the "Description" and "CustomerID" columns.</h4>"""

df_new = df.copy()

null_stock_codes = df_new[df_new['Description'].isnull()].StockCode.values

for code in null_stock_codes:
    if df_new[df_new.StockCode == code].shape[0]> 1:

        probable_desc = df_new[df_new.StockCode == code]['Description'].value_counts().index[0]

        df_new.loc[(df_new.StockCode == code) & (df_new['Description'].isnull()), 'Description'] = probable_desc

df_new.isnull().sum()



df_new.fillna(value = {'Description': 'Description not found', 'CustomerID': 0}, inplace = True)

df_new.isnull().sum()

"""<h4>

A copy of the Dataframe is created and the null values are handled.

For the Description column ->

Firstly, the Stock Code for each Null Description is recorded and checked to see if the product exists for other transactions. If it exists, then the most common Description for that Stock Code is imputed in place of the Null Description. If it doesn't exist, the Description is replaced with the string 'Description not found'.

For the CustomerID column ->

The Null values are replaced with 0. Research was done to find some similarity, in the using InvoiceDate column. However, I was not able to find a connection.

</h4>
"""

df_new.duplicated().sum()

"""<h4>There's 5268 Duplicate values in the dataset. </h4>"""

df_new.shape

df_new = df_new.drop_duplicates()

df_new.shape

"""<h4>The duplicated values are handled by deleting them.</h4>

<b> Invoice Column </b>
"""

df_new.InvoiceNo.nunique()

"""From 01/12/2010 to 09/12/2011, they have made <b> 25900 </b> new transactions, which may or may not have involved the same customers.

<b> Stock Code Column </b>
"""

df_new.StockCode.nunique()

df_new.StockCode.value_counts()

fig, ax = plt.subplots()

sold_item_counts = df_new.StockCode.value_counts()[:10]

sold_item_counts.plot(kind = 'bar', title = 'Top 10 items sold by the Retail (BY CODE)', xlabel = 'Code of the Item', ylabel = 'Quantity Sold')

plt.xticks(rotation = 45, ha = 'right')

plt.show()

"""The Retail has <b> 4070 </b> Different and Unique items in their stock.

The most sold item is the Item with the <b>Code 85123A</b>.

<b> Quantity of Items Column </b>
"""

df.Quantity.value_counts()

df.Quantity.max()

df.Quantity.mean()

df[df.Quantity ==80995]

"""On average, the Retail sells around <b> 10 items </b> to each customer.

However, the most common number of Items sold in one Transaction is <b> 1 </b>, which happened <b> 148227 times </b>.

The maximum number of items sold in one transaction by the Retail is <b> 80995 </b> . The item was <b> PAPER CRAFT, LITTLE BIRDIE <b> , which has a unit price of 2.08.

<b> Description Column </b>
"""

df_new.Description.nunique()

df_new.Description.value_counts()

fig, ax = plt.subplots()

sold_item_counts = df_new.Description.value_counts()[:5]

sold_item_counts.plot(kind = 'bar', title = 'Top 5 items sold by the Retail (BY NAME)', xlabel = 'Name of the Item', ylabel = 'Quantity Sold')

plt.xticks(rotation = 45,fontsize = 10,  ha = 'right')

plt.show()

"""We can come to the conclusion that the <b> "WHITE HANGING HEART T-LIGHT HOLDER" </b> is the most sold item for this retail.

However, there is a mismatch in the Unique Numbers for Stock Code and Description columns.

This means that each stock code can have multiple entries in the "Description" column.

It also suggests that the "WHITE HANGING HEART T-LIGHT HOLDER" can be present under different Stock Codes.

<b>DATE and TIME COLUMN </b>
"""

date_format = '%m/%d/%Y %H:%M'
df_new['invoice_date'] = df_new['InvoiceDate'].apply(lambda x: datetime.strptime(x, date_format))

df_new.drop(['InvoiceDate'], axis = 1, inplace = True)

df_new.sample(3)

df_new.dtypes

df_new.invoice_date.value_counts().index[0]

"""The most transactions that took place in this retail happened exactly at <b> 2.41 pm on the 31st of October, 2011.</b>

<b> Unit Price column </b>
"""

df_new.UnitPrice.describe()

df_new.UnitPrice.value_counts()

df_new[df_new.UnitPrice == df_new.UnitPrice.max()]

"""The <b> Average Unit Price </b> of the products of this Retail is <b> 4.63 pounds </b>

The highest Unit Price of a product sold by the Retail is <b> 38970 </b>.

However, after further research it looks like it isn't an actual product. Further research is required.

<b> COUNTRY column </b>
"""

fig, ax = plt.subplots()

sold_item_counts = df_new.Country.value_counts()[:10]

sold_item_counts.plot(kind = 'bar', title = 'Top 10 Countries According to Most Transactions', xlabel = 'Country', ylabel = 'Number of Transactions')
plt.xticks(rotation=45, ha='right')

plt.show()

df.Country.nunique()

"""<b> United Kingdom </b> is where most of the transaction takes place for this retail. That is understandable, because the Retail is based on the United Kingdom itself.

Apart from the UK, the countries with which the retail has blooming business with are <b> Germany and France. </b>

Furthermore, the Retail had conducted business with <b> 38 </b> different countries during the given timeframe.

<b> CustomerID column </b>
"""

df_new.CustomerID = df_new.CustomerID.astype(int)

fig, ax = plt.subplots()

customer_counts = df_new.CustomerID.value_counts()[1:11]

customer_counts.plot(kind = 'bar', title = 'Top 10 Customers (By Transaction)', xlabel = 'Customer ID', ylabel = 'Number of Transactions')
plt.xticks(rotation=45, ha='right')

plt.show()

"""The Retail store did the most business with <b>Customer ID 17841</b>. The Customer made almost <b> 8000 transactions</b> in the given timeframe.

This detail is only for Customers who are registered.

<h3>CANCELED INVOICES</h3>
"""

canceled_invoice_index = []

canceled_invoices = []

for index, entry in enumerate(df_new.InvoiceNo):

    if 'C' in entry[0]:

        canceled_invoice_index.append(index)
        canceled_invoices.append(entry)

len(canceled_invoices)

canceled_invoice_df = df_new.iloc[canceled_invoice_index]

canceled_invoice_df

fig, ax = plt.subplots()

transaction_quantity = [df_new.shape[0],canceled_invoice_df.shape[0]]

labels = ['Total', 'Canceled']

colors = ['#ff9999','#66b3ff']

plt.pie(transaction_quantity, labels = labels,autopct='%1.1f%%', colors = colors,startangle=140)

plt.title('Percentage of Canceled Invoices')

plt.show()

canceled_invoice_df.CustomerID.value_counts()[1:2]

"""The Customer with the most Canceled Invoices is <b> CustomerID 14911 </b>, with a total of <b> 226 cancels </b>"""

canceled_invoice_df.Description.value_counts()

fig, ax = plt.subplots()

canceled_product_counts = canceled_invoice_df.Description.value_counts()[:5]

canceled_product_counts.plot(kind = 'bar', title = 'Top 5 Canceled Invoices', xlabel = 'Product Description', ylabel = 'Number of Canceled Invoices')
plt.xticks(rotation=45, ha='right')

plt.show()

"""The Products With the most Canceled Invoices are <b> Manual </b> and <b>REGENCY CAKESTAND 3 TIER </b>"""

df_new.head()

df_new.shape

index_labels_to_drop = df_new.index[canceled_invoice_index]

df_s = df_new.drop(index_labels_to_drop)

df_s.shape

df_s.sample(5)

"""<h5><b>Removing elements that have values less than 0 in the 'Quantity' column, 'Unit Price' column</h3>"""

less_than_zero_quantity = df_s[df_s.Quantity < 0].index

less_than_zero_unit_price = df_s[df_s.UnitPrice < 0].index

df_s.drop(less_than_zero_quantity, inplace = True)
df_s.drop(less_than_zero_unit_price, inplace = True)

df_s.shape

"""<h5><b>Removing elements with letters in the 'InvoiceNo' column, which indicates unsuccessful transactions</h3>"""

invoice_with_letters_index = []

for index, entry in enumerate(df_s.InvoiceNo):

    try:

        temp = int(entry)

    except ValueError:
        invoice_with_letters_index.append(index)

df_s.drop(invoice_with_letters_index, inplace = True)

df_s.to_csv('cleaned_ecommerce_data.csv', index=False)

#df_s.to_csv('Cleaned_E_Comm_Dataset.csv')

"""<h2> <b> Popularity-Based Recommendation System </b></h2>"""

most_sold_items = df_s.groupby(['Description', 'StockCode'])['Quantity'].sum().reset_index().sort_values(by = 'Quantity', ascending = False)

top_10_most_sold = most_sold_items[:10]
top_10_most_sold

"""<h3> The above recommendation system is based on the most Popular products of the E-commerce store. They can be recommended to all users, since they are the most sold products, which suggests that these products are Top Quality.</h3>"""

data_from_past_year = df_s[df_s.invoice_date > datetime(2010,12,31)]



most_sold_items_recent = data_from_past_year.groupby(['Description','StockCode'])['Quantity'].sum().reset_index().sort_values(by = 'Quantity', ascending = False)

top_10_most_sold_from_past_year = most_sold_items_recent[:10]
top_10_most_sold_from_past_year

"""<h3> This recommendation system is based on the most Popular products of the E-commerce store from the past year. These products are currently Trending in the store. They can be recommended to all users, since they are the most sold products, which suggests that these products are Top Quality.  <br><br>

It can be concluded that all of "PAPER CRAFT", "MEDIUM CERAMIC TOP STORAGE JAR" have been sold in the year of 2011, and not in 2010. These are the most TRENDING products.

</h3>

<h2><b>Item-Based Collaborative Filtering<b></h2>
"""

df_s.CustomerID.nunique()

df_with_customer_id = df_s[df_s['CustomerID'] > 0]

df_with_customer_id.head()

user_item_matrix = df_with_customer_id.pivot_table(index = 'CustomerID', columns = 'Description', values = 'Quantity', aggfunc = 'sum', fill_value = 0)

random_index = random.randint(0,3876)
product_chosen_at_random = user_item_matrix.columns[random_index]


print(f'The product chosen at random for testing purposes is - {product_chosen_at_random}')

item_similarity = cosine_similarity(user_item_matrix.T)
item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns)

similar_items_for_item_based_collaborative_filtering = item_similarity_df[product_chosen_at_random].sort_values(ascending=False)[1:11].index.tolist()

print(f"""

The top 10 Products based on Item-Based Collaborative Filtering, for the Product: {product_chosen_at_random} are:

{', '.join(similar_items_for_item_based_collaborative_filtering)}

""")

"""<h3> This recommendation system recommends items by analyzing the TOTAL QUANTITY PURCHASED for items based on the Users' previous SPENDINGS. <br><br>

If a User Frequently purchases certain products together, this system will suggest those products as part of the Recommendation system.

</h3>

<h2><b>User-Based Collaborative Filtering<b></h2>
"""

item_user_matrix = df_with_customer_id.pivot_table(index = 'Description', columns = 'CustomerID', values = 'Quantity', aggfunc = 'sum', fill_value = 0)

#user_item_matrix = df_with_customer_id.pivot_table(index = 'CustomerID', columns = 'Description', values = 'Quantity', aggfunc = 'sum', fill_value = 0)

from scipy.sparse import csr_matrix

user_item_matrix_csr = csr_matrix(item_user_matrix.values)

from sklearn.neighbors import NearestNeighbors

model_knn = NearestNeighbors(metric = 'cosine', algorithm = 'brute')
model_knn.fit(user_item_matrix_csr)

distances, indices = model_knn.kneighbors(item_user_matrix.iloc[random_index,:].values.reshape(1, -1), n_neighbors = 10)

similar_items_for_user_based_collaborative_filtering = []

for i in range(1, len(distances.flatten())):
    similar_items_for_user_based_collaborative_filtering.append(item_user_matrix.index[indices.flatten()[i]])

print(f"""

The top 10 Products based on Item-Based Collaborative Filtering, for the Product: {product_chosen_at_random} are:

{', '.join(similar_items_for_user_based_collaborative_filtering)}

""")

"""<h3> This recommendation system ecommends items by finding users who have similar tastes or preferences. It suggests items that similar users have purchased, assuming that if two users have agreed on certain items, they are likely to purchase other Similar products.

</h3>

<h2><b>Content-Based Filtering<b></h2>
"""

# from sklearn.feature_extraction.text import TfidfVectorizer


# tfv = TfidfVectorizer(min_df=1,  max_features=None,
#             strip_accents='unicode', analyzer='word',token_pattern=r'\w{1,}',
#             ngram_range=(1, 3),
#             stop_words = 'english')

# tfidf_matrix = tfv.fit_transform(df_s['Description'])

#description_similarity = cosine_similarity(tfidf_matrix)

# from sklearn.decomposition import TruncatedSVD

# svd = TruncatedSVD(n_components=100, random_state=42)
# tfidf_matrix_reduced = svd.fit_transform(tfidf_matrix)

# description_similarity_sparse = csr_matrix(tfidf_matrix_reduced)
# description_similarity = cosine_similarity(description_similarity_sparse)

# description_similarity = cosine_similarity(description_similarity_sparse)

"""<h3>Due to Computational Limitations, it wasn't possible to develop this system.</h3>

<h2><b>Hybrid Recommendation System<b></h2>

<h4>Combining the Recommendation Systems developed to provide more Comprehensive Recommendation.</h4>
"""

#POPULARITY BASED SYSTEM

most_sold_items = df_s.groupby(['Description', 'StockCode'])['Quantity'].sum().reset_index().sort_values(by='Quantity', ascending=False)
top_10_most_sold = most_sold_items[:10]

# RECENT-POPULARITY BASED SYSTEM
data_from_past_year = df_s[df_s['invoice_date'] > datetime(2010, 12, 31)]
most_sold_items_recent = data_from_past_year.groupby(['Description', 'StockCode'])['Quantity'].sum().reset_index().sort_values(by='Quantity', ascending=False)

"""<h5>FOR CHOOSING A RANDOM PRODUCT TO TEST THE RECOMMENDATION SYSTEM, WE CHOOSE A RANDOM INDEX </h5>"""

random_index = random.randint(0, user_item_matrix.shape[1]-1)

#ITEM-BASED COLLOBORATIVE FILTERING

#TAKING ONLY CUSTOMERS WHO HAVE CUSTOMER ID
df_with_customer_id = df_s[df_s['CustomerID'] > 0]

user_item_matrix = df_with_customer_id.pivot_table(index='CustomerID', columns='Description', values='Quantity', aggfunc='sum', fill_value=0)

product_chosen_at_random = user_item_matrix.columns[random_index]

item_similarity = cosine_similarity(user_item_matrix.T)
item_similarity_df = pd.DataFrame(item_similarity, index=user_item_matrix.columns, columns=user_item_matrix.columns)
similar_items_item_based = item_similarity_df[product_chosen_at_random].sort_values(ascending=False)[1:11].index.tolist()

product_chosen_at_random

#USER-BASED COLLOBORATIVE FILTERING

item_user_matrix = df_with_customer_id.pivot_table(index='Description', columns='CustomerID', values='Quantity', aggfunc='sum', fill_value=0)
user_item_matrix_csr = csr_matrix(item_user_matrix.values)
model_knn = NearestNeighbors(metric='cosine', algorithm='brute')
model_knn.fit(user_item_matrix_csr)

distances, indices = model_knn.kneighbors(item_user_matrix.iloc[random_index, :].values.reshape(1, -1), n_neighbors=10)
similar_items_user_based = [item_user_matrix.index[indices.flatten()[i]] for i in range(1, len(distances.flatten()))]

"""<h4> To develop the hybrid model, we'll set scores for the Prodcuts Recommended by Each System. <br><br>

From there, we'll normalize the scores, so that they can be comparable. <br><br>

After that, we will consider the scores for each product, add them together (or aggregate them) and the total score will be the Final Recommendation Score. <br><br>

We will be using the scores of the RECENT-POPULARITY BASED SYSTEM, USER-BASED COLLOBORATIVE FILTERING SYSTEM, and ITEM-BASED COLLOBORATIVE FILTERING system only.

</h4>
"""

# popularity_scores = {row['Description']: row['Quantity'] for _, row in most_sold_items.iterrows()}
recent_popularity_scores = {row['Description']: row['Quantity'] for _, row in most_sold_items_recent.iterrows()}
item_based_scores = {item: score for item, score in zip(similar_items_item_based, range(10, 0, -1))}
user_based_scores = {item: score for item, score in zip(similar_items_user_based, range(10, 0, -1))}

"""<h4> The scores are extracted above.</h4>"""

def normalize_scores(scores):
    max_score = max(scores.values())
    min_score = min(scores.values())
    normalized = {key: (value - min_score) / (max_score - min_score) for key, value in scores.items()}
    return normalized


#popularity_scores_normalized = normalize_scores(popularity_scores)
recent_popularity_scores_normalized = normalize_scores(recent_popularity_scores)
item_based_scores_normalized = normalize_scores(item_based_scores)
user_based_scores_normalized = normalize_scores(user_based_scores)

"""<h4>The scores are normalized above.</h4>"""

def aggregate_scores(*score_dicts):
    aggregate = {}
    for score_dict in score_dicts:
        for item, score in score_dict.items():
            if item not in aggregate:
                aggregate[item] = 0
            aggregate[item] += score
    return aggregate

final_scores = aggregate_scores(recent_popularity_scores_normalized, item_based_scores_normalized, user_based_scores_normalized)

"""<h4>The scores are Added Together above and stored as Dictionary in the "final_scores".</h4>"""

top_hybrid_recommendations = sorted(final_scores.items(), key=lambda x: x[1], reverse=True)[:10]

"""<h4><b>Top 10 Products To Be Recommended</b></h4>"""

products = []
for product in top_hybrid_recommendations:
    products.append(product[0])

print(f"""

The Product which is Considered is: {product_chosen_at_random}

""")

print(f"""

The final products to be recommended are:

{', '.join(products)}

""")

